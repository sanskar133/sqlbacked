services:
  chat_backend:
    build:
      context: chat_backend
      dockerfile: Dockerfile
    volumes:
      - /db/prequel_ai_volume/:/chat_backend/prequel_ai_volume
      - /mlruns:/chat_backend/mlruns # <-- mount mlruns
    ports:
      - 5000:5000
    env_file:
      - chat_backend/.env

  fabric_analytics_frontend:
    image: fabric_analytics_frontend
    build:
      context: fabric_analytics_frontend
      dockerfile: Dockerfile
    ports:
      - 3002:3002
    depends_on:
      - chat_backend
